{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from h5py import File\n",
    "import pandas as pd\n",
    "\n",
    "# load CLIP from huggingface, load the first N images and extract the features\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THINGS_normMUA_F.mat',\n",
       " 'THINGS_normMUA_N.mat',\n",
       " 'THINGS_MUA_trials_N.mat',\n",
       " 'THINGS_MUA_trials_F.mat',\n",
       " 'THINGS_normMUA.mat',\n",
       " 'things_imgs_F.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path =\"/home/matteo/storage/THINGS_Monkey\"\n",
    "monkey = \"F\"\n",
    "os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_imgs = File(opj(base_path,f'things_imgs_{monkey}.mat'))\n",
    "train_imgs = things_imgs['train_imgs']   # group object --> <HDF5 group \"/train_imgs\" (3 members)>\n",
    "test_imgs = things_imgs['test_imgs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_reference(hdf5_file, ref):\n",
    "    \"\"\"\n",
    "    Resolve an HDF5 dataset reference and convert it into a string.\n",
    "    \"\"\"\n",
    "    data = hdf5_file[ref][:]\n",
    "    return ''.join(chr(i) for i in data.flatten() if i > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_local_paths = []\n",
    "train_things_paths = []\n",
    "\n",
    "test_classes = []\n",
    "test_local_paths = []\n",
    "test_things_paths = []\n",
    "\n",
    "with File(opj(base_path, f\"things_imgs_{monkey}.mat\")) as f:\n",
    "    train_imgs = f['train_imgs']\n",
    "    \n",
    "    train_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['class']]\n",
    "    train_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['local_path']]\n",
    "    train_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['things_path']]\n",
    "\n",
    "    test_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['class']]\n",
    "    test_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['local_path']]\n",
    "    test_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['things_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#trial_idx</th>\n",
       "      <th>#train_idx</th>\n",
       "      <th>#test_idx</th>\n",
       "      <th>#rep</th>\n",
       "      <th>#count</th>\n",
       "      <th>#correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15094.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>25244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>25245.0</td>\n",
       "      <td>13906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>25246.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>25247.0</td>\n",
       "      <td>15559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>25248.0</td>\n",
       "      <td>20602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25248 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #trial_idx  #train_idx  #test_idx  #rep  #count  #correct\n",
       "0             1.0     16504.0        0.0   1.0     1.0       1.0\n",
       "1             2.0     16470.0        0.0   1.0     2.0       1.0\n",
       "2             3.0     15094.0        0.0   1.0     3.0       1.0\n",
       "3             4.0      2514.0        0.0   1.0     4.0       1.0\n",
       "4             5.0      4860.0        0.0   1.0     1.0       1.0\n",
       "...           ...         ...        ...   ...     ...       ...\n",
       "25243     25244.0         0.0       40.0  30.0     1.0       4.0\n",
       "25244     25245.0     13906.0        0.0   1.0     2.0       4.0\n",
       "25245     25246.0       470.0        0.0   1.0     3.0       4.0\n",
       "25246     25247.0     15559.0        0.0   1.0     4.0       4.0\n",
       "25247     25248.0     20602.0        0.0   1.0     1.0       4.0\n",
       "\n",
       "[25248 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = File(opj(base_path, f\"THINGS_MUA_trials_{monkey}.mat\"))\n",
    "df =pd.DataFrame(trials[\"ALLMAT\"][:].T, columns=[\"#trial_idx\", \"#train_idx\", \"#test_idx\", \"#rep\", \"#count\", \"#correct\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 25248, 1024)\n"
     ]
    }
   ],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy', data)\n",
    "data = np.load('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy')\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing_base_path =\"/home/matteo/storage/THINGS_img/\"\n",
    "N = 15000      # TODO: prenderli tutti (dati training)\n",
    "\n",
    "train_indices = df[df[\"#train_idx\"]!=0][\"#train_idx\"].values.astype(int) - 1\n",
    "test_indices = df[df[\"#test_idx\"]!=0][\"#test_idx\"].values.astype(int) - 1\n",
    "\n",
    "sorted_train_img_path = [train_things_paths[i] for i in train_indices]\n",
    "sorted_test_img_path = [test_things_paths[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 59/59 [13:32<00:00, 13.78s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:41<00:00,  3.42s/it]\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def extract_features(model, images):\n",
    "    images = [Image.open(img).convert(\"RGB\") for img in images]\n",
    "    inputs = processor(images= images, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.get_image_features(**inputs)\n",
    "    return outputs\n",
    "\n",
    "batch = 256\n",
    "train_features = []\n",
    "test_features = []\n",
    "\n",
    "for i in tqdm.trange(0, N, batch):\n",
    "    features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_train_img_path[i:i+batch]])\n",
    "    train_features.append(features.cpu().numpy())\n",
    "\n",
    "for i in tqdm.trange(0, len(sorted_test_img_path), batch):\n",
    "    features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_test_img_path[i:i+batch]])\n",
    "    test_features.append(features.cpu().numpy())\n",
    "\n",
    "train_features = np.concatenate(train_features, axis=0)[:N]\n",
    "test_features = np.concatenate(test_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy', train_features)\n",
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy', test_features)\n",
    "\n",
    "train_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy')\n",
    "test_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 512), (3000, 512))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 15000, 1024) (300, 3000, 1024)\n"
     ]
    }
   ],
   "source": [
    "neural_train_trial_idx = df[df[\"#train_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "neural_test_trial_idx = df[df[\"#test_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "\n",
    "train_neural = data[:,neural_train_trial_idx[:N]]     \n",
    "test_neural = data[:,neural_test_trial_idx]\n",
    "print(train_neural.shape, test_neural.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg activity over repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 84.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 100, 1024) (100, 512) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_neural_avg = []\n",
    "test_features_avg = []\n",
    "selected_test_imgs = []\n",
    "for idx in tqdm.tqdm(np.unique(test_indices)):\n",
    "    test_neural_avg.append(test_neural[:,test_indices==idx].mean(1))\n",
    "    #same for the test features\n",
    "    test_features_avg.append(test_features[test_indices==idx].mean(0))\n",
    "    selected_test_imgs.append(np.array(sorted_test_img_path)[test_indices==idx][0])\n",
    "\n",
    "test_neural_avg = np.array(test_neural_avg).transpose(1,0,-1)\n",
    "test_features_avg = np.array(test_features_avg)\n",
    "selected_test_imgs = np.array(selected_test_imgs)\n",
    "\n",
    "print(test_neural_avg.shape, test_features_avg.shape, selected_test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 100, 1024), (100, 512), (15000, 512), (300, 15000, 1024))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neural_avg.shape, test_features_avg.shape, train_features.shape, train_neural.shape     # TODO: primi 100 di prestimolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
