{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from h5py import File\n",
    "import pandas as pd\n",
    "\n",
    "# load CLIP from huggingface, load the first N images and extract the features\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THINGS_normMUA_F.mat',\n",
       " 'THINGS_normMUA_N.mat',\n",
       " 'THINGS_MUA_trials_N.mat',\n",
       " 'THINGS_MUA_trials_F.mat',\n",
       " 'THINGS_normMUA.mat',\n",
       " 'things_imgs_F.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path =\"/home/matteo/storage/THINGS_Monkey\"\n",
    "monkey = \"F\"\n",
    "os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_imgs = File(opj(base_path,f'things_imgs_{monkey}.mat'))\n",
    "train_imgs = things_imgs['train_imgs']   # group object --> <HDF5 group \"/train_imgs\" (3 members)>\n",
    "test_imgs = things_imgs['test_imgs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_reference(hdf5_file, ref):\n",
    "    \"\"\"\n",
    "    Resolve an HDF5 dataset reference and convert it into a string.\n",
    "    \"\"\"\n",
    "    data = hdf5_file[ref][:]\n",
    "    return ''.join(chr(i) for i in data.flatten() if i > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_local_paths = []\n",
    "train_things_paths = []\n",
    "\n",
    "test_classes = []\n",
    "test_local_paths = []\n",
    "test_things_paths = []\n",
    "\n",
    "with File(opj(base_path, f\"things_imgs_{monkey}.mat\")) as f:\n",
    "    train_imgs = f['train_imgs']\n",
    "    \n",
    "    train_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['class']]\n",
    "    train_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['local_path']]\n",
    "    train_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['things_path']]\n",
    "\n",
    "    test_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['class']]\n",
    "    test_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['local_path']]\n",
    "    test_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['things_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#trial_idx</th>\n",
       "      <th>#train_idx</th>\n",
       "      <th>#test_idx</th>\n",
       "      <th>#rep</th>\n",
       "      <th>#count</th>\n",
       "      <th>#correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15094.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>25244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>25245.0</td>\n",
       "      <td>13906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>25246.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>25247.0</td>\n",
       "      <td>15559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>25248.0</td>\n",
       "      <td>20602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25248 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #trial_idx  #train_idx  #test_idx  #rep  #count  #correct\n",
       "0             1.0     16504.0        0.0   1.0     1.0       1.0\n",
       "1             2.0     16470.0        0.0   1.0     2.0       1.0\n",
       "2             3.0     15094.0        0.0   1.0     3.0       1.0\n",
       "3             4.0      2514.0        0.0   1.0     4.0       1.0\n",
       "4             5.0      4860.0        0.0   1.0     1.0       1.0\n",
       "...           ...         ...        ...   ...     ...       ...\n",
       "25243     25244.0         0.0       40.0  30.0     1.0       4.0\n",
       "25244     25245.0     13906.0        0.0   1.0     2.0       4.0\n",
       "25245     25246.0       470.0        0.0   1.0     3.0       4.0\n",
       "25246     25247.0     15559.0        0.0   1.0     4.0       4.0\n",
       "25247     25248.0     20602.0        0.0   1.0     1.0       4.0\n",
       "\n",
       "[25248 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = File(opj(base_path, f\"THINGS_MUA_trials_{monkey}.mat\"))\n",
    "df =pd.DataFrame(trials[\"ALLMAT\"][:].T, columns=[\"#trial_idx\", \"#train_idx\", \"#test_idx\", \"#rep\", \"#count\", \"#correct\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 25248, 1024)\n"
     ]
    }
   ],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy', data)\n",
    "data = np.load('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy')\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing_base_path = \"/home/matteo/storage/THINGS_img/\"\n",
    "N = 15000      # TODO: prenderli tutti (dati training)\n",
    "\n",
    "train_indices = df[df[\"#train_idx\"]!=0][\"#train_idx\"].values.astype(int) - 1\n",
    "test_indices = df[df[\"#test_idx\"]!=0][\"#test_idx\"].values.astype(int) - 1\n",
    "\n",
    "sorted_train_img_path = [train_things_paths[i] for i in train_indices]\n",
    "sorted_test_img_path = [test_things_paths[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# def extract_features(model, images):\n",
    "#     images = [Image.open(img).convert(\"RGB\") for img in images]\n",
    "#     inputs = processor(images= images, return_tensors=\"pt\", padding=True)\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.get_image_features(**inputs)\n",
    "#     return outputs\n",
    "\n",
    "# batch = 256\n",
    "# train_features = []\n",
    "# test_features = []\n",
    "\n",
    "# for i in tqdm.trange(0, N, batch):\n",
    "#     features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_train_img_path[i:i+batch]])\n",
    "#     train_features.append(features.cpu().numpy())\n",
    "\n",
    "# for i in tqdm.trange(0, len(sorted_test_img_path), batch):\n",
    "#     features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_test_img_path[i:i+batch]])\n",
    "#     test_features.append(features.cpu().numpy())\n",
    "\n",
    "# train_features = np.concatenate(train_features, axis=0)[:N]\n",
    "# test_features = np.concatenate(test_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy', train_features)\n",
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy', test_features)\n",
    "\n",
    "train_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy')\n",
    "test_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 512), (3000, 512))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 15000, 1024) (300, 3000, 1024)\n"
     ]
    }
   ],
   "source": [
    "neural_train_trial_idx = df[df[\"#train_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "neural_test_trial_idx = df[df[\"#test_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "\n",
    "train_neural = data[:,neural_train_trial_idx[:N]]      # prendo tutte le osservazioni --> no data[:,neural_train_trial_idx[:N]]     \n",
    "test_neural = data[:,neural_test_trial_idx]\n",
    "print(train_neural.shape, test_neural.shape)     # SHAPE: num_timepoints, observation, electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg activity over repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 84.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 100, 1024) (100, 512) (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_neural_avg = []\n",
    "test_features_avg = []\n",
    "selected_test_imgs = []\n",
    "for idx in tqdm.tqdm(np.unique(test_indices)):\n",
    "    test_neural_avg.append(test_neural[:,test_indices==idx].mean(1))\n",
    "    #same for the test features\n",
    "    test_features_avg.append(test_features[test_indices==idx].mean(0))\n",
    "    selected_test_imgs.append(np.array(sorted_test_img_path)[test_indices==idx][0])\n",
    "\n",
    "test_neural_avg = np.array(test_neural_avg).transpose(1,0,-1)\n",
    "test_features_avg = np.array(test_features_avg)\n",
    "selected_test_imgs = np.array(selected_test_imgs)\n",
    "\n",
    "print(test_neural_avg.shape, test_features_avg.shape, selected_test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 100, 1024), (100, 512), (15000, 512), (300, 15000, 1024))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neural_avg.shape, test_features_avg.shape, train_features.shape, train_neural.shape     # TODO: primi 100 di prestimolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neural = train_neural[100:]  # (200, 15000, 1024)\n",
    "test_neural_avg = test_neural_avg[100:]  # (200, 100, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "\n",
    "class TemporalNeuralToFeature(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=768, output_dim=512, num_layers=1, tau=0.05, lr=1e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, bidirectional=False)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(output_dim, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.tau = tau\n",
    "        self.lr = lr\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_out, _ = self.rnn(x)  # rnn_out: (batch, time, hidden)\n",
    "        final_hidden = rnn_out[:, -1, :]  \n",
    "        # final_hidden = torch.mean(rnn_out, dim=1)\n",
    "        return self.mlp(final_hidden)\n",
    "    \n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    \n",
    "\n",
    "class SimpleTCN(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-3, tau=0.05):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (batch, 1024, 200)\n",
    "        x = self.conv(x).squeeze(-1)  # (batch, 128)\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerNeuralToFeature(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, d_model=256, nhead=8, num_layers=4, output_dim=512, tau=0.05, lr=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.input_proj = nn.Linear(input_dim, self.d_model)\n",
    "        self.pos_encoding = PositionalEncoding(self.d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=nhead, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)  # mean pooling across time\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.d_model, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.tau = tau\n",
    "        self.lr = lr\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):  # x: (batch, time, channels)\n",
    "        x = self.input_proj(x)         # â†’ (batch, time, d_model)\n",
    "        x = self.pos_encoding(x)       # + positional encodings\n",
    "        x = self.transformer(x).reshape(x.shape[0], self.d_model, -1)       # â†’ (batch, d_model, time)\n",
    "        x = self.pooling(x).squeeze(-1)              # mean pooling across time\n",
    "        return self.mlp(x)             # â†’ (batch, output_dim)\n",
    "    \n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True) \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_size = 256\n",
    "device = 'cuda:1'\n",
    "cuda_d = 1\n",
    "seed = 42\n",
    "\n",
    "X_train = train_neural.transpose(1, 0, 2)  \n",
    "Y_train = train_features  \n",
    "X_test = test_neural_avg.transpose(1, 0, 2)  # shape: (15000, 200, 1024)\n",
    "Y_test = test_features_avg \n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "# X_reshaped = X_train.reshape(-1, X_train.shape[-1])  # (15000*200, 1024)\n",
    "X_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_scaled = scaler_X.fit_transform(X_reshaped)\n",
    "X_train_tensor = torch.tensor(X_scaled.reshape(15000, 200, 1024), dtype=torch.float32, device=device)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1) \n",
    "X_test_scaled = scaler_X.fit_transform(X_test_reshaped)\n",
    "X_test_tensor = torch.tensor(X_test_scaled.reshape(100, 200, 1024), dtype=torch.float32, device=device)\n",
    "\n",
    "dataset = TensorDataset(X_train_tensor, torch.tensor(Y_train, dtype=torch.float32, device=device))\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.tensor(Y_test, dtype=torch.float32, device=device))\n",
    "val_size = int(0.2 * len(dataset))  \n",
    "train_size = len(dataset) - val_size\n",
    "generator1 = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import geomloss \n",
    "\n",
    "\n",
    "class SoftMapping(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-3, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.attn_linear = nn.Linear(input_dim, 1)\n",
    "        self.attn_linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        # attn_weights = torch.softmax(self.attn_linear(x), dim=1)\n",
    "        attn_weights = torch.sigmoid(self.attn_linear(x))\n",
    "        attn_out = torch.sum(attn_weights * x, dim=1)\n",
    "        # x_mean = x.mean(dim=1)  # (batch, 1024)\n",
    "        output = self.mlp(attn_out)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "\n",
    "class LinearFlatTime(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024*200, output_dim=512, lr=1e-3, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        x = x.reshape(x.shape[0], -1)  \n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"train_loss\", mse_loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return mse_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"val_loss\", mse_loss, on_epoch=True, prog_bar=True)\n",
    "        return mse_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "class MlpAvgTime(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-4, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, output_dim)\n",
    "        )\n",
    "        self.linear = nn.Sequential(     # TODO: provare OT + CL in questo caso qua\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        x = x.mean(dim=1)  \n",
    "        output = self.mlp(x)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"train_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss_cl\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"val_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        return loss_cl\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteoc/miniconda3/envs/speech-meg/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | attn_linear  | Sequential | 262 K \n",
      "1 | mlp          | Sequential | 524 K \n",
      "2 | loss_mse     | MSELoss    | 0     \n",
      "  | other params | n/a        | 1     \n",
      "--------------------------------------------\n",
      "787 K     Trainable params\n",
      "0         Non-trainable params\n",
      "787 K     Total params\n",
      "3.150     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 91.43it/s, v_num=5, train_loss_step=4.030, tau=0.0491, val_loss=4.150, train_loss_epoch=4.810]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 4.151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 89.29it/s, v_num=5, train_loss_step=3.100, tau=0.0458, val_loss=3.570, train_loss_epoch=3.480]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.585 >= min_delta = 0.1. New best score: 3.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 89.48it/s, v_num=5, train_loss_step=2.520, tau=0.0427, val_loss=3.260, train_loss_epoch=2.750]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.301 >= min_delta = 0.1. New best score: 3.265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 90.03it/s, v_num=5, train_loss_step=2.140, tau=0.0399, val_loss=3.140, train_loss_epoch=2.220] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.125 >= min_delta = 0.1. New best score: 3.140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 90.94it/s, v_num=5, train_loss_step=1.500, tau=0.0354, val_loss=3.010, train_loss_epoch=1.500] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.133 >= min_delta = 0.1. New best score: 3.007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 91.06it/s, v_num=5, train_loss_step=0.176, tau=0.024, val_loss=3.030, train_loss_epoch=0.188]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 3.007. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 81.79it/s, v_num=5, train_loss_step=0.176, tau=0.024, val_loss=3.030, train_loss_epoch=0.188]\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed, workers=True)\n",
    "model = SoftMapping()\n",
    "logger = CSVLogger(\"/home/matteoc/nlinear-monkeys/logs/\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.10, patience=10, verbose=True, mode=\"min\")\n",
    "trainer = Trainer(max_epochs=35, devices=[cuda_d], logger=logger, callbacks=[early_stop_callback])  # Usa GPU se disponibile, 35 epoche per il SoftMapping\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = logger.log_dir + \"/metrics.csv\"\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "val_loss_df = df[~df[\"val_loss\"].isna()]\n",
    "train_loss_df = df[~df[\"train_loss_epoch\"].isna()]\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.array(train_loss_df[\"epoch\"]), np.array(train_loss_df[\"train_loss_epoch\"]), label=\"Train Loss\")\n",
    "plt.plot(np.array(val_loss_df[\"epoch\"]), np.array(val_loss_df[\"val_loss\"]), label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoftMapping(\n",
    "#   (attn_linear): Sequential(\n",
    "#     (0): Linear(in_features=1024, out_features=256, bias=True)\n",
    "#     (1): ReLU()\n",
    "#     (2): Dropout(p=0.5, inplace=False)\n",
    "#     (3): Linear(in_features=256, out_features=1, bias=True)\n",
    "#   )\n",
    "#   (mlp): Sequential(\n",
    "#     (0): Linear(in_features=1024, out_features=512, bias=True)\n",
    "#   )\n",
    "#   (contrastive_loss): Learnable Tau\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# SoftMapping --> nonLinear/time **\n",
    "# Top-1 accuracy: 68/100 (68.00%)       \n",
    "# Top-3 accuracy: 91/100 (91.00%)    \n",
    "\n",
    "# Baseline - Matteo --> linear/avgTime\n",
    "# Top-1 accuracy: 57/100 (57.00%)\n",
    "# Top-3 accuracy: 89/100 (89.00%)\n",
    "\n",
    "# Baseline CL --> linear/flatTime\n",
    "# Top-1 accuracy: 51/100 (51.00%)\n",
    "# Top-3 accuracy: 84/100 (84.00%)\n",
    "\n",
    "# Baseline CL --> nonLinear/avgTime\n",
    "# Top-1 accuracy: 59/100 (59.00%)\n",
    "# Top-3 accuracy: 86/100 (86.00%)\n",
    "\n",
    "# Baseline MSE --> nonLinear/avgTime\n",
    "# Top-1 accuracy: 29/100 (29.00%)\n",
    "# Top-3 accuracy: 54/100 (54.00%)\n",
    "\n",
    "# SoftMapping - MSE\n",
    "# Top-1 accuracy: 31/100 (31.00%)\n",
    "# Top-3 accuracy: 66/100 (66.00%)\n",
    "\n",
    "# SimpleTCN\n",
    "# Top-1 accuracy: 49/100 (49.00%)\n",
    "# Top-3 accuracy: 85/100 (85.00%)\n",
    "\n",
    "# TempralNeuraToFeature (GRU)\n",
    "# Top-1 accuracy: 27/100 (27.00%)\n",
    "# Top-3 accuracy: 61/100 (61.00%)\n",
    "\n",
    "# TransformerNeuralToFeature\n",
    "# Top-1 accuracy: 34/100 (34.00%)\n",
    "# Top-3 accuracy: 72/100 (72.00%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_dir = \"/srv/nfs-data/sisko/matteoc/monkeys/\"\n",
    "# torch.save(model.state_dict(), f\"{tgt_dir}/softmapping_state_dict.pt\")\n",
    "# torch.save(model.attn_linear.state_dict(), f\"{tgt_dir}/attn_linear.pt\")\n",
    "# torch.save(model.mlp.state_dict(), f\"{tgt_dir}/mlp.pt\")\n",
    "# print(model.tau)\n",
    "# print(model.lr)\n",
    "\n",
    "# clone_model = SoftMapping(input_dim=1024, output_dim=512, lr=1e-3, tau=0.05).to(device)\n",
    "# state_dict = torch.load(f\"{tgt_dir}/softmapping_state_dict.pt\")\n",
    "# attn_linear_state_dict = torch.load(f\"{tgt_dir}/attn_linear.pt\")\n",
    "# mlp_state_dict = torch.load(f\"{tgt_dir}/mlp.pt\")\n",
    "# clone_model.load_state_dict(state_dict)\n",
    "# clone_model.attn_linear.load_state_dict(attn_linear_state_dict)\n",
    "# clone_model.mlp.load_state_dict(mlp_state_dict)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for x, y in test_loader:\n",
    "#         model_original = model.to(device)\n",
    "#         y_hat_original = model_original(x)\n",
    "#         y_hat_clone = clone_model(x)\n",
    "#         assert torch.allclose(y_hat_original, y_hat_clone, atol=1e-6), \"Mismatch negli output!\"\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "\n",
    "# - fare una PCA rispetto alla dimensione degli elettrodi, e valutare come aumentando la dimensione (aumenta info degli elettrodi) aumentano le performance;\n",
    "# - provare una linear regression sulle dimensioni flattizzate (timepoints indipendenti - lineare/tempo) --> le performance dovrebbero essere peggio\n",
    "# - provare una mlp sul dato neurale dove la dimensione tempo Ã¨ mediata (nonlineare/nontempo)\n",
    "# - (nonlineare/tempo) Ã¨ quella che ho applicato io, (lineare/nontempo) Ã¨ la baseline di Matteo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 87.74it/s]\n"
     ]
    }
   ],
   "source": [
    "x,y=next(iter(test_loader))\n",
    "\n",
    "y_pred=[]\n",
    "y_true=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm.tqdm(test_loader):\n",
    "        clone_model_ent = model.to(device)\n",
    "        y_hat = clone_model_ent(x)\n",
    "        y_true.append(y)\n",
    "        y_pred.append(y_hat)\n",
    "y_pred=torch.cat(y_pred,0)\n",
    "y_true=torch.cat(y_true,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 68/100 (68.00%)\n",
      "Top-3 accuracy: 91/100 (91.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "y_true_np = y_true.cpu().numpy()\n",
    "y_pred_np = y_pred.cpu().numpy()\n",
    "nbrs = NearestNeighbors(n_neighbors=5, metric='cosine').fit(y_true_np)\n",
    "\n",
    "distances, top_indices = nbrs.kneighbors(y_pred_np)\n",
    "true_indices = torch.arange(len(y_true_np)).cpu().numpy()\n",
    "\n",
    "top1_count = (top_indices[:, 0] == true_indices).sum()\n",
    "top3_count = sum(true_idx in top_indices[i] for i, true_idx in enumerate(true_indices))\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1_count}/{len(y_true_np)} ({top1_count / len(y_true_np) * 100:.2f}%)\")\n",
    "print(f\"Top-3 accuracy: {top3_count}/{len(y_true_np)} ({top3_count / len(y_true_np) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
