{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "from os.path import join as opj\n",
    "from h5py import File\n",
    "import pandas as pd\n",
    "\n",
    "# load CLIP from huggingface, load the first N images and extract the features\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THINGS_normMUA_F.mat',\n",
       " 'THINGS_normMUA_N.mat',\n",
       " 'THINGS_MUA_trials_N.mat',\n",
       " 'THINGS_MUA_trials_F.mat',\n",
       " 'THINGS_normMUA.mat',\n",
       " 'things_imgs_F.mat']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path =\"/home/matteo/storage/THINGS_Monkey\"\n",
    "monkey = \"F\"\n",
    "os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_imgs = File(opj(base_path,f'things_imgs_{monkey}.mat'))\n",
    "train_imgs = things_imgs['train_imgs']   # group object --> <HDF5 group \"/train_imgs\" (3 members)>\n",
    "test_imgs = things_imgs['test_imgs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_reference(hdf5_file, ref):\n",
    "    \"\"\"\n",
    "    Resolve an HDF5 dataset reference and convert it into a string.\n",
    "    \"\"\"\n",
    "    data = hdf5_file[ref][:]\n",
    "    return ''.join(chr(i) for i in data.flatten() if i > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = []\n",
    "train_local_paths = []\n",
    "train_things_paths = []\n",
    "\n",
    "test_classes = []\n",
    "test_local_paths = []\n",
    "test_things_paths = []\n",
    "\n",
    "with File(opj(base_path, f\"things_imgs_{monkey}.mat\")) as f:\n",
    "    train_imgs = f['train_imgs']\n",
    "    \n",
    "    train_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['class']]\n",
    "    train_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['local_path']]\n",
    "    train_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['train_imgs']['things_path']]\n",
    "\n",
    "    test_classes = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['class']]\n",
    "    test_local_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['local_path']]\n",
    "    test_things_paths = [resolve_reference(things_imgs, ref[0]) for ref in things_imgs['test_imgs']['things_path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#trial_idx</th>\n",
       "      <th>#train_idx</th>\n",
       "      <th>#test_idx</th>\n",
       "      <th>#rep</th>\n",
       "      <th>#count</th>\n",
       "      <th>#correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>16470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>15094.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2514.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25243</th>\n",
       "      <td>25244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25244</th>\n",
       "      <td>25245.0</td>\n",
       "      <td>13906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25245</th>\n",
       "      <td>25246.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25246</th>\n",
       "      <td>25247.0</td>\n",
       "      <td>15559.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25247</th>\n",
       "      <td>25248.0</td>\n",
       "      <td>20602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25248 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #trial_idx  #train_idx  #test_idx  #rep  #count  #correct\n",
       "0             1.0     16504.0        0.0   1.0     1.0       1.0\n",
       "1             2.0     16470.0        0.0   1.0     2.0       1.0\n",
       "2             3.0     15094.0        0.0   1.0     3.0       1.0\n",
       "3             4.0      2514.0        0.0   1.0     4.0       1.0\n",
       "4             5.0      4860.0        0.0   1.0     1.0       1.0\n",
       "...           ...         ...        ...   ...     ...       ...\n",
       "25243     25244.0         0.0       40.0  30.0     1.0       4.0\n",
       "25244     25245.0     13906.0        0.0   1.0     2.0       4.0\n",
       "25245     25246.0       470.0        0.0   1.0     3.0       4.0\n",
       "25246     25247.0     15559.0        0.0   1.0     4.0       4.0\n",
       "25247     25248.0     20602.0        0.0   1.0     1.0       4.0\n",
       "\n",
       "[25248 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trials = File(opj(base_path, f\"THINGS_MUA_trials_{monkey}.mat\"))\n",
    "df =pd.DataFrame(trials[\"ALLMAT\"][:].T, columns=[\"#trial_idx\", \"#train_idx\", \"#test_idx\", \"#rep\", \"#count\", \"#correct\"])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 25248, 1024)\n"
     ]
    }
   ],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy', data)\n",
    "data = np.load('/srv/nfs-data/sisko/matteoc/monkeys/trials_allmua.npy')\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "thing_base_path = \"/home/matteo/storage/THINGS_img/\"\n",
    "N = 15000      # TODO: prenderli tutti (dati training)\n",
    "\n",
    "train_indices = df[df[\"#train_idx\"]!=0][\"#train_idx\"].values.astype(int) - 1\n",
    "test_indices = df[df[\"#test_idx\"]!=0][\"#test_idx\"].values.astype(int) - 1\n",
    "\n",
    "sorted_train_img_path = [train_things_paths[i] for i in train_indices]\n",
    "sorted_test_img_path = [test_things_paths[i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(device)\n",
    "# processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# def extract_features(model, images):\n",
    "#     images = [Image.open(img).convert(\"RGB\") for img in images]\n",
    "#     inputs = processor(images= images, return_tensors=\"pt\", padding=True)\n",
    "#     inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model.get_image_features(**inputs)\n",
    "#     return outputs\n",
    "\n",
    "# batch = 256\n",
    "# train_features = []\n",
    "# test_features = []\n",
    "\n",
    "# for i in tqdm.trange(0, N, batch):\n",
    "#     features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_train_img_path[i:i+batch]])\n",
    "#     train_features.append(features.cpu().numpy())\n",
    "\n",
    "# for i in tqdm.trange(0, len(sorted_test_img_path), batch):\n",
    "#     features = extract_features(model, [opj(thing_base_path,\"THINGS\",\"Images\", img).replace(\"\\\\\",\"/\") for img in sorted_test_img_path[i:i+batch]])\n",
    "#     test_features.append(features.cpu().numpy())\n",
    "\n",
    "# train_features = np.concatenate(train_features, axis=0)[:N]\n",
    "# test_features = np.concatenate(test_features, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy', train_features)\n",
    "# np.save('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy', test_features)\n",
    "\n",
    "train_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/train_features.npy')\n",
    "test_features = np.load('/srv/nfs-data/sisko/matteoc/monkeys/test_features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 512), (3000, 512))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 15000, 1024) (300, 3000, 1024)\n"
     ]
    }
   ],
   "source": [
    "neural_train_trial_idx = df[df[\"#train_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "neural_test_trial_idx = df[df[\"#test_idx\"]!=0][\"#trial_idx\"].values.astype(int) - 1\n",
    "\n",
    "train_neural = data[:,neural_train_trial_idx[:N]]      # prendo tutte le osservazioni --> no data[:,neural_train_trial_idx[:N]]     \n",
    "test_neural = data[:,neural_test_trial_idx]\n",
    "print(train_neural.shape, test_neural.shape)     # SHAPE: num_timepoints, observation, electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avg activity over repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:01<00:00, 77.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 100, 1024) (100, 512) (100,)\n"
     ]
    }
   ],
   "source": [
    "test_neural_avg = []\n",
    "test_features_avg = []\n",
    "selected_test_imgs = []\n",
    "for idx in tqdm.tqdm(np.unique(test_indices)):\n",
    "    test_neural_avg.append(test_neural[:,test_indices==idx].mean(1))\n",
    "    #same for the test features\n",
    "    test_features_avg.append(test_features[test_indices==idx].mean(0))\n",
    "    selected_test_imgs.append(np.array(sorted_test_img_path)[test_indices==idx][0])\n",
    "\n",
    "test_neural_avg = np.array(test_neural_avg).transpose(1,0,-1)\n",
    "test_features_avg = np.array(test_features_avg)\n",
    "selected_test_imgs = np.array(selected_test_imgs)\n",
    "\n",
    "print(test_neural_avg.shape, test_features_avg.shape, selected_test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300, 100, 1024), (100, 512), (15000, 512), (300, 15000, 1024))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_neural_avg.shape, test_features_avg.shape, train_features.shape, train_neural.shape     # TODO: primi 100 di prestimolo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neural = train_neural[100:]  # (200, 15000, 1024)\n",
    "test_neural_avg = test_neural_avg[100:]  # (200, 100, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "    \n",
    "\n",
    "class TemporalNeuralToFeature(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, hidden_dim=768, output_dim=512, num_layers=1, tau=0.05, lr=1e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers,\n",
    "                          batch_first=True, bidirectional=False)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(output_dim, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.tau = tau\n",
    "        self.lr = lr\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_out, _ = self.rnn(x)  # rnn_out: (batch, time, hidden)\n",
    "        final_hidden = rnn_out[:, -1, :]  \n",
    "        # final_hidden = torch.mean(rnn_out, dim=1)\n",
    "        return self.mlp(final_hidden)\n",
    "    \n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "    \n",
    "\n",
    "class SimpleTCN(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-3, tau=0.05):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(input_dim, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool1d(1)\n",
    "        )\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)  # (batch, 1024, 200)\n",
    "        x = self.conv(x).squeeze(-1)  # (batch, 128)\n",
    "        return self.mlp(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div_term)\n",
    "        pe[:, 1::2] = torch.cos(pos * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :].to(x.device)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class TransformerNeuralToFeature(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, d_model=256, nhead=8, num_layers=4, output_dim=512, tau=0.05, lr=1e-3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.input_proj = nn.Linear(input_dim, self.d_model)\n",
    "        self.pos_encoding = PositionalEncoding(self.d_model)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=self.d_model, nhead=nhead, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)  # mean pooling across time\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.d_model, output_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(output_dim, output_dim)\n",
    "        )\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.tau = tau\n",
    "        self.lr = lr\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(self.tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):  # x: (batch, time, channels)\n",
    "        x = self.input_proj(x)         # â†’ (batch, time, d_model)\n",
    "        x = self.pos_encoding(x)       # + positional encodings\n",
    "        x = self.transformer(x).reshape(x.shape[0], self.d_model, -1)       # â†’ (batch, d_model, time)\n",
    "        x = self.pooling(x).squeeze(-1)              # mean pooling across time\n",
    "        return self.mlp(x)             # â†’ (batch, output_dim)\n",
    "    \n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True) \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        preds = self(x)\n",
    "        loss_mse = self.loss_fn(preds, y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(preds, y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "batch_size = 256\n",
    "device = 'cuda:2'\n",
    "cuda_d = 2\n",
    "seed = 42\n",
    "\n",
    "X_train = train_neural.transpose(1, 0, 2)  \n",
    "Y_train = train_features  \n",
    "X_test = test_neural_avg.transpose(1, 0, 2)  # shape: (15000, 200, 1024)\n",
    "Y_test = test_features_avg \n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "X_reshaped = X_train.reshape(-1, X_train.shape[-1])  \n",
    "# X_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_scaled = scaler_X.fit_transform(X_reshaped)\n",
    "X_train_tensor = torch.tensor(X_scaled.reshape(15000, 200, 1024), dtype=torch.float32, device=device)\n",
    "X_test_reshaped = X_test.reshape(-1, X_test.shape[-1]) \n",
    "X_test_scaled = scaler_X.transform(X_test_reshaped)\n",
    "X_test_tensor = torch.tensor(X_test_scaled.reshape(100, 200, 1024), dtype=torch.float32, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train_tensor, torch.tensor(Y_train, dtype=torch.float32, device=device))\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.tensor(Y_test, dtype=torch.float32, device=device))\n",
    "val_size = int(0.2 * len(dataset))  \n",
    "train_size = len(dataset) - val_size\n",
    "generator1 = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import geomloss \n",
    "\n",
    "\n",
    "class LinearFlatTime(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024*200, output_dim=512, lr=1e-3, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        x = x.reshape(x.shape[0], -1)  \n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"train_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss_cl\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"val_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        return loss_cl\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    \n",
    "\n",
    "class MlpAvgTime(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-4, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(768, output_dim)\n",
    "        )\n",
    "        self.linear = nn.Sequential(     # TODO: provare OT + CL in questo caso qua\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        x = x.mean(dim=1)  \n",
    "        output = self.linear(x)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"train_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss_cl\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss_cl = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        mse_loss = self.loss_mse(self(x), y)\n",
    "        self.log(\"val_loss\", loss_cl, on_epoch=True, prog_bar=True)\n",
    "        return loss_cl\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMapping(pl.LightningModule):\n",
    "    def __init__(self, input_dim=1024, output_dim=512, lr=1e-4, tau=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attn_mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "        self.attn_linear = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.lin = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim)\n",
    "        )\n",
    "        self.loss_mse = nn.MSELoss()\n",
    "        self.lr = lr\n",
    "        self.tau = tau\n",
    "        self.log_tau = nn.Parameter(torch.tensor(np.log(tau), dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):     # shape: (batch, 200, 1024)\n",
    "        # attn_weights = torch.softmax(self.attn_linear(x), dim=1)\n",
    "        attn_weights = torch.sigmoid(self.attn_linear(x))\n",
    "        attn_out = torch.mean(attn_weights * x, dim=1)\n",
    "        output = self.lin(attn_out)\n",
    "        return output\n",
    "\n",
    "    def cosine_similarity_matrix(self, A, B):\n",
    "        A_norm = F.normalize(A, dim=1)\n",
    "        B_norm = F.normalize(B, dim=1)\n",
    "        return torch.mm(A_norm, B_norm.T)\n",
    "\n",
    "    def contrastive_loss_nt(self, S, tau):\n",
    "        tau = torch.exp(self.log_tau)  \n",
    "        S_exp = torch.exp(S / tau)\n",
    "        loss = -torch.log(torch.diag(S_exp) / S_exp.sum(dim=1))\n",
    "        return loss.mean()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_fn(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"train_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"tau\", torch.exp(self.log_tau).item(), prog_bar=True)  \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        # loss = self.loss_cl(self(x), y)\n",
    "        cos_matrix = self.cosine_similarity_matrix(self(x), y)\n",
    "        loss = self.contrastive_loss_nt(cos_matrix, self.tau)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteoc/miniconda3/envs/speech-meg/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | attn_mlp     | Sequential | 262 K \n",
      "1 | attn_linear  | Sequential | 1.0 K \n",
      "2 | lin          | Sequential | 524 K \n",
      "3 | loss_mse     | MSELoss    | 0     \n",
      "  | other params | n/a        | 1     \n",
      "--------------------------------------------\n",
      "788 K     Trainable params\n",
      "0         Non-trainable params\n",
      "788 K     Total params\n",
      "3.154     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 136.85it/s, v_num=74, train_loss_step=4.960, tau=0.0501, val_loss=5.100, train_loss_epoch=5.380]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 151.59it/s, v_num=74, train_loss_step=4.480, tau=0.0498, val_loss=4.710, train_loss_epoch=4.840]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.387 >= min_delta = 0.09. New best score: 4.714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 164.15it/s, v_num=74, train_loss_step=4.280, tau=0.0494, val_loss=4.420, train_loss_epoch=4.430]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.296 >= min_delta = 0.09. New best score: 4.418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 165.16it/s, v_num=74, train_loss_step=3.960, tau=0.0491, val_loss=4.220, train_loss_epoch=4.130]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.196 >= min_delta = 0.09. New best score: 4.222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 164.62it/s, v_num=74, train_loss_step=3.670, tau=0.0487, val_loss=4.060, train_loss_epoch=3.900]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.158 >= min_delta = 0.09. New best score: 4.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 165.10it/s, v_num=74, train_loss_step=3.550, tau=0.0484, val_loss=3.940, train_loss_epoch=3.700]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.119 >= min_delta = 0.09. New best score: 3.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 164.34it/s, v_num=74, train_loss_step=3.300, tau=0.048, val_loss=3.840, train_loss_epoch=3.540] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.107 >= min_delta = 0.09. New best score: 3.838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 157.11it/s, v_num=74, train_loss_step=3.170, tau=0.0474, val_loss=3.680, train_loss_epoch=3.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.158 >= min_delta = 0.09. New best score: 3.680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 166.50it/s, v_num=74, train_loss_step=2.940, tau=0.0468, val_loss=3.550, train_loss_epoch=3.040]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.127 >= min_delta = 0.09. New best score: 3.552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 172.22it/s, v_num=74, train_loss_step=2.740, tau=0.0462, val_loss=3.460, train_loss_epoch=2.850]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.091 >= min_delta = 0.09. New best score: 3.461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 166.37it/s, v_num=74, train_loss_step=2.560, tau=0.0453, val_loss=3.340, train_loss_epoch=2.610]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.117 >= min_delta = 0.09. New best score: 3.345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 161.69it/s, v_num=74, train_loss_step=2.240, tau=0.0443, val_loss=3.230, train_loss_epoch=2.350]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.111 >= min_delta = 0.09. New best score: 3.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 181.84it/s, v_num=74, train_loss_step=1.940, tau=0.043, val_loss=3.140, train_loss_epoch=2.070] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.098 >= min_delta = 0.09. New best score: 3.136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 188.02it/s, v_num=74, train_loss_step=1.690, tau=0.0414, val_loss=3.040, train_loss_epoch=1.760]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.097 >= min_delta = 0.09. New best score: 3.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 166.38it/s, v_num=74, train_loss_step=1.330, tau=0.0393, val_loss=2.960, train_loss_epoch=1.420]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 3.039. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 143.89it/s, v_num=74, train_loss_step=1.330, tau=0.0393, val_loss=2.960, train_loss_epoch=1.420]\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed, workers=True)\n",
    "model = SoftMapping()\n",
    "logger = CSVLogger(\"/home/matteoc/nlinear-monkeys/logs/\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.09, patience=10, verbose=True, mode=\"min\")\n",
    "trainer = Trainer(max_epochs=50, devices=[cuda_d], logger=logger, callbacks=[early_stop_callback])  \n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_path = logger.log_dir + \"/metrics.csv\"\n",
    "df = pd.read_csv(log_path)\n",
    "\n",
    "val_loss_df = df[~df[\"val_loss\"].isna()]\n",
    "train_loss_df = df[~df[\"train_loss_epoch\"].isna()]\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(np.array(train_loss_df[\"epoch\"]), np.array(train_loss_df[\"train_loss_epoch\"]), label=\"Train Loss\")\n",
    "plt.plot(np.array(val_loss_df[\"epoch\"]), np.array(val_loss_df[\"val_loss\"]), label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training vs Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SoftMapping(\n",
    "#   (attn_mlp): Sequential(\n",
    "#     (0): Linear(in_features=1024, out_features=256, bias=True)\n",
    "#     (1): GELU(approximate='none')\n",
    "#     (2): Dropout(p=0.5, inplace=False)\n",
    "#     (3): Linear(in_features=256, out_features=1, bias=True)\n",
    "#   )\n",
    "#   (attn_linear): Sequential(\n",
    "#     (0): Linear(in_features=1024, out_features=1, bias=True)\n",
    "#     (1): Dropout(p=0.5, inplace=False)\n",
    "#   )\n",
    "#   (lin): Sequential(\n",
    "#     (0): Linear(in_features=1024, out_features=512, bias=True)\n",
    "#   )\n",
    "#   (loss_mse): MSELoss()\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# SoftMapping - MSE\n",
    "# Top-1 accuracy: 31/100 (31.00%)\n",
    "# Top-3 accuracy: 66/100 (66.00%)\n",
    "\n",
    "# SimpleTCN\n",
    "# Top-1 accuracy: 49/100 (49.00%)\n",
    "# Top-3 accuracy: 85/100 (85.00%)\n",
    "\n",
    "# TempralNeuraToFeature (GRU)\n",
    "# Top-1 accuracy: 27/100 (27.00%)\n",
    "# Top-3 accuracy: 61/100 (61.00%)\n",
    "\n",
    "# TransformerNeuralToFeature\n",
    "# Top-1 accuracy: 34/100 (34.00%)\n",
    "# Top-3 accuracy: 72/100 (72.00%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tgt_dir = \"/srv/nfs-data/sisko/matteoc/monkeys/\"\n",
    "# torch.save(model.state_dict(), f\"{tgt_dir}/softmapping_state_dict.pt\")\n",
    "# torch.save(model.attn_linear.state_dict(), f\"{tgt_dir}/attn_linear.pt\")\n",
    "# torch.save(model.mlp.state_dict(), f\"{tgt_dir}/mlp.pt\")\n",
    "# print(model.tau)\n",
    "# print(model.lr)\n",
    "\n",
    "# clone_model = SoftMapping(input_dim=1024, output_dim=512, lr=1e-3, tau=0.05).to(device)\n",
    "# state_dict = torch.load(f\"{tgt_dir}/softmapping_state_dict.pt\")\n",
    "# attn_linear_state_dict = torch.load(f\"{tgt_dir}/attn_linear.pt\")\n",
    "# mlp_state_dict = torch.load(f\"{tgt_dir}/mlp.pt\")\n",
    "# clone_model.load_state_dict(state_dict)\n",
    "# clone_model.attn_linear.load_state_dict(attn_linear_state_dict)\n",
    "# clone_model.mlp.load_state_dict(mlp_state_dict)\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for x, y in test_loader:\n",
    "#         model_original = model.to(device)\n",
    "#         y_hat_original = model_original(x)\n",
    "#         y_hat_clone = clone_model(x)\n",
    "#         assert torch.allclose(y_hat_original, y_hat_clone, atol=1e-6), \"Mismatch negli output!\"\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 618.26it/s]\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(test_loader))\n",
    "\n",
    "y_pred=[]\n",
    "y_true=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm.tqdm(test_loader):\n",
    "        clone_model_ent = model.to(device)\n",
    "        y_hat = clone_model_ent(x)\n",
    "        y_true.append(y)\n",
    "        y_pred.append(y_hat)\n",
    "y_pred=torch.cat(y_pred,0)\n",
    "y_true=torch.cat(y_true,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 64/100 (64.00%)\n",
      "Top-5 accuracy: 88/100 (88.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "y_true_np = y_true.cpu().numpy()\n",
    "y_pred_np = y_pred.cpu().numpy()\n",
    "nbrs = NearestNeighbors(n_neighbors=5, metric='cosine').fit(y_true_np)\n",
    "\n",
    "distances, top_indices = nbrs.kneighbors(y_pred_np)\n",
    "true_indices = torch.arange(len(y_true_np)).cpu().numpy()\n",
    "\n",
    "top1_count = (top_indices[:, 0] == true_indices).sum()\n",
    "top3_count = sum(true_idx in top_indices[i] for i, true_idx in enumerate(true_indices))\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1_count}/{len(y_true_np)} ({top1_count / len(y_true_np) * 100:.2f}%)\")\n",
    "print(f\"Top-5 accuracy: {top3_count}/{len(y_true_np)} ({top3_count / len(y_true_np) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Channels Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(667,)\n"
     ]
    }
   ],
   "source": [
    "top_global_channels = torch.load('/srv/nfs-data/sisko/storage/THINGS_img/top_global_channels_F.pt')\n",
    "print(top_global_channels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_global_channels_mv = np.array([t.item() for t in top_global_channels])\n",
    "\n",
    "X_train_tensor = X_train_tensor[:, :, top_global_channels_mv]\n",
    "X_test_tensor = X_test_tensor[:, :, top_global_channels_mv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_train_tensor, torch.tensor(train_features, dtype=torch.float32, device=device))\n",
    "test_dataset = TensorDataset(X_test_tensor, torch.tensor(test_features_avg, dtype=torch.float32, device=device))\n",
    "val_size = int(0.2 * len(dataset))  \n",
    "train_size = len(dataset) - val_size\n",
    "generator1 = torch.Generator().manual_seed(seed)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator1)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteoc/miniconda3/envs/speech-meg/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | linear       | Sequential | 68.3 M\n",
      "1 | loss_mse     | MSELoss    | 0     \n",
      "  | other params | n/a        | 1     \n",
      "--------------------------------------------\n",
      "68.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "68.3 M    Total params\n",
      "273.205   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 85.06it/s, v_num=67, train_loss_step=4.900, tau=0.0512, val_loss=5.050, train_loss_epoch=5.360]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 63.50it/s, v_num=67, train_loss_step=3.650, tau=0.0489, val_loss=4.270, train_loss_epoch=4.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.777 >= min_delta = 0.1. New best score: 4.270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 83.85it/s, v_num=67, train_loss_step=1.580, tau=0.0451, val_loss=3.480, train_loss_epoch=2.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.794 >= min_delta = 0.1. New best score: 3.476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 85.17it/s, v_num=67, train_loss_step=0.00826, tau=0.0404, val_loss=3.850, train_loss_epoch=0.00775]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 3.476. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:05<00:00,  8.80it/s, v_num=67, train_loss_step=0.00826, tau=0.0404, val_loss=3.850, train_loss_epoch=0.00775]\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed, workers=True)\n",
    "# model_top_channels = SoftMapping(input_dim=667)\n",
    "# model_top_channels = MlpAvgTime(input_dim=667)\n",
    "model_top_channels = LinearFlatTime(input_dim=667*200)\n",
    "logger = CSVLogger(\"/home/matteoc/nlinear-monkeys/logs/\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.10, patience=10, verbose=True, mode=\"min\")\n",
    "trainer = Trainer(max_epochs=50, devices=[cuda_d], logger=logger, callbacks=[early_stop_callback])  # Usa GPU se disponibile, 35 epoche per il SoftMapping\n",
    "trainer.fit(model_top_channels, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "x,y = next(iter(test_loader))\n",
    "\n",
    "y_pred=[]\n",
    "y_true=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x,y in tqdm.tqdm(test_loader):\n",
    "        model_top = model_top_channels.to(device)\n",
    "        y_hat = model_top(x)\n",
    "        y_true.append(y)\n",
    "        y_pred.append(y_hat)\n",
    "y_pred=torch.cat(y_pred,0)\n",
    "y_true=torch.cat(y_true,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 47/100 (47.00%)\n",
      "Top-5 accuracy: 77/100 (77.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "y_true_np = y_true.cpu().numpy()\n",
    "y_pred_np = y_pred.cpu().numpy()\n",
    "nbrs = NearestNeighbors(n_neighbors=5, metric='cosine').fit(y_true_np)\n",
    "\n",
    "distances, top_indices = nbrs.kneighbors(y_pred_np)\n",
    "true_indices = torch.arange(len(y_true_np)).cpu().numpy()\n",
    "\n",
    "top1_count = (top_indices[:, 0] == true_indices).sum()\n",
    "top3_count = sum(true_idx in top_indices[i] for i, true_idx in enumerate(true_indices))\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1_count}/{len(y_true_np)} ({top1_count / len(y_true_np) * 100:.2f}%)\")\n",
    "print(f\"Top-5 accuracy: {top3_count}/{len(y_true_np)} ({top3_count / len(y_true_np) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_components = 32\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca_flat = pca.fit_transform(X_scaled) \n",
    "X_train_pca = X_train_pca_flat.reshape(X_train.shape[0], X_train.shape[1], n_components)\n",
    "\n",
    "X_test_pca_flat = pca.transform(X_test_scaled)\n",
    "X_test_pca = X_test_pca_flat.reshape(X_test.shape[0], X_test.shape[1], n_components)\n",
    "\n",
    "X_train_tensor_pca = torch.tensor(X_train_pca.reshape(15000, 200, n_components), dtype=torch.float32, device=device)\n",
    "X_test_tensor_pca = torch.tensor(X_test_pca.reshape(100, 200, n_components), dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_pca = TensorDataset(X_train_tensor_pca, torch.tensor(Y_train, dtype=torch.float32, device=device))\n",
    "test_dataset_pca = TensorDataset(X_test_tensor_pca, torch.tensor(Y_test, dtype=torch.float32, device=device))\n",
    "val_size = int(0.2 * len(dataset_pca))  \n",
    "train_size = len(dataset_pca) - val_size\n",
    "generator1 = torch.Generator().manual_seed(seed)\n",
    "train_dataset_pca, val_dataset_pca = random_split(dataset_pca, [train_size, val_size], generator=generator1)\n",
    "\n",
    "train_loader_pca = DataLoader(train_dataset_pca, batch_size=batch_size, shuffle=True)\n",
    "val_loader_pca = DataLoader(val_dataset_pca, batch_size=batch_size, shuffle=False)\n",
    "test_loader_pca = DataLoader(test_dataset_pca, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/matteoc/miniconda3/envs/speech-meg/lib/python3 ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name         | Type       | Params\n",
      "--------------------------------------------\n",
      "0 | attn_mlp     | Sequential | 8.7 K \n",
      "1 | attn_linear  | Sequential | 33    \n",
      "2 | lin          | Sequential | 16.9 K\n",
      "3 | loss_mse     | MSELoss    | 0     \n",
      "  | other params | n/a        | 1     \n",
      "--------------------------------------------\n",
      "25.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.6 K    Total params\n",
      "0.103     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=255` in the `DataLoader` to improve performance.\n",
      "/home/matteoc/miniconda3/envs/speech-meg/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:293: The number of training batches (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 190.42it/s, v_num=73, train_loss_step=5.530, tau=0.0502, val_loss=5.640, train_loss_epoch=5.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 5.642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 163.05it/s, v_num=73, train_loss_step=5.420, tau=0.0508, val_loss=5.550, train_loss_epoch=5.580]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.091 >= min_delta = 0.09. New best score: 5.551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 163.86it/s, v_num=73, train_loss_step=5.320, tau=0.0513, val_loss=5.450, train_loss_epoch=5.460]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.102 >= min_delta = 0.09. New best score: 5.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 163.23it/s, v_num=73, train_loss_step=5.190, tau=0.0513, val_loss=5.350, train_loss_epoch=5.360]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.094 >= min_delta = 0.09. New best score: 5.355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 150.66it/s, v_num=73, train_loss_step=5.150, tau=0.0506, val_loss=5.240, train_loss_epoch=5.230]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.111 >= min_delta = 0.09. New best score: 5.244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 149.21it/s, v_num=73, train_loss_step=4.960, tau=0.0492, val_loss=5.140, train_loss_epoch=5.120]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.106 >= min_delta = 0.09. New best score: 5.138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 149.95it/s, v_num=73, train_loss_step=4.790, tau=0.0476, val_loss=5.040, train_loss_epoch=5.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.100 >= min_delta = 0.09. New best score: 5.038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 149.84it/s, v_num=73, train_loss_step=4.770, tau=0.046, val_loss=4.940, train_loss_epoch=4.890] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.093 >= min_delta = 0.09. New best score: 4.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 163.25it/s, v_num=73, train_loss_step=4.620, tau=0.0442, val_loss=4.840, train_loss_epoch=4.770]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.103 >= min_delta = 0.09. New best score: 4.842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 162.74it/s, v_num=73, train_loss_step=4.510, tau=0.0426, val_loss=4.750, train_loss_epoch=4.650]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.093 >= min_delta = 0.09. New best score: 4.749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 161.68it/s, v_num=73, train_loss_step=4.490, tau=0.0409, val_loss=4.650, train_loss_epoch=4.530]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.096 >= min_delta = 0.09. New best score: 4.653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 184.05it/s, v_num=73, train_loss_step=4.290, tau=0.0391, val_loss=4.560, train_loss_epoch=4.400]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.094 >= min_delta = 0.09. New best score: 4.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 176.48it/s, v_num=73, train_loss_step=4.170, tau=0.0371, val_loss=4.460, train_loss_epoch=4.270]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.095 >= min_delta = 0.09. New best score: 4.464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 154.66it/s, v_num=73, train_loss_step=4.010, tau=0.0352, val_loss=4.390, train_loss_epoch=4.160]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 4.464. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47/47 [00:00<00:00, 149.80it/s, v_num=73, train_loss_step=4.010, tau=0.0352, val_loss=4.390, train_loss_epoch=4.160]\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(seed, workers=True)\n",
    "model_pca = SoftMapping(input_dim=n_components, output_dim=512, lr=1e-4, tau=0.05)\n",
    "logger = CSVLogger(\"/home/matteoc/nlinear-monkeys/logs/\", name=\"my_model\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.09, patience=10, verbose=True, mode=\"min\")\n",
    "trainer = Trainer(max_epochs=100, devices=[cuda_d], logger=logger, callbacks=[early_stop_callback])  \n",
    "trainer.fit(model_pca, train_loader_pca, val_loader_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ridge = X_scaled.reshape(15000, 200, 1024)\n",
    "X_test_ridge = X_test_scaled.reshape(100, 200, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_global_channels_mv = np.array([t.item() for t in top_global_channels])\n",
    "\n",
    "X_train_ridge = X_train_ridge[:, :, top_global_channels_mv]\n",
    "X_test_ridge = X_test_ridge[:, :, top_global_channels_mv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 200, 1024),\n",
       " (100, 200, 1024),\n",
       " 2.8071032442955614e-15,\n",
       " 0.9999999999999949,\n",
       " -0.012036878,\n",
       " 0.47685653)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ridge.shape, X_test_ridge.shape, X_train_ridge.mean(), X_train_ridge.std(), Y_train.mean(), Y_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from himalaya.ridge import RidgeCV\n",
    "from himalaya.backend import set_backend\n",
    "\n",
    "vm = RidgeCV(alphas=[0.1,1,10,30,50,100,300])  \n",
    "\n",
    "device_id = 1\n",
    "backend = set_backend(\"torch_cuda\")\n",
    "X_train_F = backend.asarray(torch.tensor(X_train_ridge).float().mean(dim=1).to(f'cuda:{device_id}'))\n",
    "Y_train_F = backend.asarray(torch.tensor(Y_train).float().to(f'cuda:{device_id}')) \n",
    "X_test_F = backend.asarray(torch.tensor(X_test_ridge).float().mean(dim=1).to(f'cuda:{device_id}'))     \n",
    "\n",
    "vm.fit(X_train_F, Y_train_F)\n",
    "y_pred_F = vm.predict(X_test_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 37/100 (37.00%)\n",
      "Top-5 accuracy: 69/100 (69.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "y_true_np = y_true.cpu().numpy()\n",
    "nbrs = NearestNeighbors(n_neighbors=5, metric='cosine').fit(y_true_np)\n",
    "\n",
    "distances, top_indices = nbrs.kneighbors(y_pred_F)\n",
    "true_indices = torch.arange(len(y_true_np)).cpu().numpy()\n",
    "\n",
    "top1_count = (top_indices[:, 0] == true_indices).sum()\n",
    "top3_count = sum(true_idx in top_indices[i] for i, true_idx in enumerate(true_indices))\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1_count}/{len(y_true_np)} ({top1_count / len(y_true_np) * 100:.2f}%)\")\n",
    "print(f\"Top-5 accuracy: {top3_count}/{len(y_true_np)} ({top3_count / len(y_true_np) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech-meg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
